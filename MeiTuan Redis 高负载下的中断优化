Redis 高负载下的中断优化
https://tech.meituan.com/2018/03/16/redis-high-concurrency-optimization.html

文章从用户的角度，发现业务高负载下，系统发生掉包的概率较大；通过网卡丢报的sysfs节点，查看到丢包统计，反过来查看kernel驱动源码，定位到丢包统计值对应的代码位置，分析引发丢包的代码上下文，发现是一个全局的堆满引起的；简单调大并不能解决丢包事件的发生，未定位到根本原因；这个堆存储到是网卡收到一次中断后，数据存储的描述信息，当收到的中断过快或者过多，而消费速度太慢便会导致这类情况发生；在系统运行时，查看网卡中断运行的线程运行情况，发现丢包基本集中在core 0上，而网卡的中断线程也基本集中在core 0上运行，至此，基本情况已经明了，服务器有两张网卡，共96个中断都集中在core 0上运行，core 0负载过高处理不过来了；使用taskset 进行绑核处理，将网卡线程绑定在指定的cpu core上，预期应当得到改善，但实际业务跑下来，丢包情况依然发生；经分析得出2，redis是一种基于内存的高速缓存业务，约1ms就会切换，业务很频繁，但当redis和网卡中断线程都运行在某一个core上时，中断线程优先级较高，频繁上下文切换，导致Redis的慢查询数量有明显上升，甚至部分业务也受到了影响，慢查询增多直接导致可用性降低；方案还需要进一步优化；后续将网卡绑定前8个core，Redis进程的亲缘性设置为剩下的所有core，也就是网卡中断处理线程和redis处理线程分别放在不同的物理core上处理。

进一步思考：为什么由操作系统默认调度的规则，网卡中断处理线程都默认集中在core 0上，可能是由于线程间具有相关性，加之‌NUMA（Non Uniform Memory Access）非一致性内存访问架构，调度到同一个物理core上，可以利用私有L1 cahche，可以更快的处理数据；其次服务器可能为多路处理器，SMP架构下，每个物理core对于总线、内存的访问能力是相同的，但是跨物理cpu之间的总线速度可能是不一样的，尽量绑定在同一个物理cpu上会有助于加速速度的处理速度。
